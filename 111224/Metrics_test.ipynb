{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d821cf53-8dcc-43f1-9622-11bef9229906",
   "metadata": {},
   "source": [
    "# Testing Metrics.py scripts from Vogt-Vincent 2024\n",
    "This is a tool devloped by Noam Vogt-Vincent in paper *coral reef potential connectivity in the southwest Indian Ocean* (2024) to process key metrics\n",
    "- Dispersal entropy\n",
    "- Dispersal strength\n",
    "- Dispersal stability \n",
    "- Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95ba0f95-1a7e-4a7a-b83b-059761847156",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nProcess, plot and export key metrics:\\n    1. Dispersal entropy\\n    2. Dispersal strength\\n    3. Dispersal stability\\n    7. Centrality\\n@author: Noam Vogt-Vincent\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Process, plot and export key metrics:\n",
    "    1. Dispersal entropy\n",
    "    2. Dispersal strength\n",
    "    3. Dispersal stability\n",
    "    7. Centrality\n",
    "@author: Noam Vogt-Vincent\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e750fafc-7bed-4084-8ac6-6c20379de7b4",
   "metadata": {},
   "source": [
    "## 1. Import pacakges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5269afff-13e5-4214-b851-a8138620c7a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Avoid importing cmasher, and networkx for now\n",
    "# In SECow, change ErrorCode to StatusCode, avoid importig numba for now \n",
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.colors as colors\n",
    "#import cmasher as cmr\n",
    "import cartopy.crs as ccrs\n",
    "#import networkx as nx\n",
    "import sys\n",
    "sys.path.insert(0, '../VogtVincent/SIM/')\n",
    "from SECoW import Matrix\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb1700b-0b58-4fd3-b158-ccefae04aa4c",
   "metadata": {},
   "source": [
    "## 2. Parameter Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7cfb2d9-cf64-48bc-8873-4c6d2b40254c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# PARAMETERS ##################################################################\n",
    "###############################################################################\n",
    "\n",
    "bio_code = sys.argv[1]\n",
    "\n",
    "# BIOLOGY\n",
    "spawning_months = [1, 2, 3, 10, 11, 12]  # Permitted spawning months\n",
    "\n",
    "# PLOTTING\n",
    "plot_full = True\n",
    "\n",
    "# DIRECTORIES\n",
    "dirs = {}\n",
    "dirs['root'] = os.getcwd() + '/../'\n",
    "dirs['matrix'] = dirs['root'] + 'MATRICES/'\n",
    "dirs['ref'] = dirs['root'] + 'REFERENCE/'\n",
    "dirs['grid'] = dirs['root'] + 'GRID_DATA/'\n",
    "dirs['fig'] = dirs['root'] + 'FIGURES/'\n",
    "\n",
    "# FILE-HANDLES\n",
    "fh = {}\n",
    "fh['flux_matrix'] = dirs['matrix'] + 'WINDS_flux_src_cell_' + bio_code + '.nc'\n",
    "fh['flux_matrix_grp'] = dirs['matrix'] + 'WINDS_flux_src_grp_' + bio_code + '.nc'\n",
    "fh['entropy_matrix'] = {'out': dirs['matrix'] + 'WINDS_src_ent_cell_' + bio_code + '.nc',\n",
    "                        'in': dirs['matrix'] + 'WINDS_snk_ent_cell_' + bio_code + '.nc'}\n",
    "fh['str_matrix'] = {'src': dirs['matrix'] + 'WINDS_src_str_cell_' + bio_code + '.nc',\n",
    "                    'snk': dirs['matrix'] + 'WINDS_snk_str_cell_' + bio_code + '.nc'}\n",
    "fh['coral'] = dirs['grid'] + 'coral_grid.nc'\n",
    "fh['grid'] = dirs['grid'] + 'griddata_winds.nc'\n",
    "fh['site_list'] = dirs['grid'] + 'site_reference_cell.csv'\n",
    "fh['site_list_grp'] = dirs['grid'] + 'site_reference_grp.xlsx'\n",
    "fh['sst'] = dirs['ref'] + 'SST/SECoW_SST.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca10523-17bc-4ebf-b75c-57751e19e449",
   "metadata": {},
   "source": [
    "## 3. Problem Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cd23c8c-2402-4b3f-8314-41646a0ada05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@>-------------------------<@\n",
      "........Preprocessing........\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# SET UP PROBLEM ##############################################################\n",
    "###############################################################################\n",
    "\n",
    "print('@>-------------------------<@')\n",
    "print('........Preprocessing........')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9c1ff59-ee43-40fc-bf83-50cdc16d0d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the flux matrix (required for several routines)\n",
    "with xr.open_dataset(fh['flux_matrix']) as file:\n",
    "    flux_obj = Matrix(file, bio_code)\n",
    "    flux_obj.label(fh['site_list'])\n",
    "    _flux = flux_obj.matrix.ns\n",
    "    _flux = _flux[:, :, _flux.month.isin(spawning_months)].sum(dim='month')\n",
    "\n",
    "    cell_list = flux_obj.matrix.source_cell.values\n",
    "\n",
    "    # Precompute source- and sink-normalised forms\n",
    "    src_flux = _flux/_flux.sum(dim='sink_cell')\n",
    "    snk_flux = _flux/_flux.sum(dim='source_cell')\n",
    "    _src_flux = src_flux.where(src_flux != 0).fillna(1.)\n",
    "    _snk_flux = snk_flux.where(snk_flux != 0).fillna(1.)\n",
    "\n",
    "    assert not np.isnan(src_flux).any()\n",
    "    assert not np.isnan(snk_flux).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ceb4e6-c274-48fe-985d-4c984d549fc4",
   "metadata": {},
   "source": [
    "## Grouping cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ee501a5-ce1a-4791-8356-d56ea944ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouped form\n",
    "with xr.open_dataset(fh['flux_matrix_grp'], chunks={'time': 1000}) as file:\n",
    "    flux_obj_grp = Matrix(file, bio_code)\n",
    "    flux_obj_grp.label(fh['site_list_grp'])\n",
    "    _flux_grp = flux_obj_grp.matrix.ns\n",
    "    _flux_grp = _flux_grp[:, :, _flux_grp.time.dt.month.isin(spawning_months)]\n",
    "\n",
    "    _flux_grp_norm = _flux_grp.sum(dim='sink_group')\n",
    "    _flux_grp_norm = _flux_grp_norm.where(_flux_grp_norm > 0).fillna(1)\n",
    "    _flux_grp = (_flux_grp/_flux_grp_norm).compute() # Sink-normalised for all applications here\n",
    "\n",
    "    _flux_grp_mean = (_flux_grp/_flux_grp.sum(dim='sink_group')).mean(dim='time').compute()\n",
    "\n",
    "    grp_list = _flux_grp.source_group.values\n",
    "\n",
    "def reorder(file):\n",
    "    # Reorder and label matrices where necessary\n",
    "    obj = Matrix(file, bio_code)\n",
    "    obj.label(fh['site_list'])\n",
    "    return obj.matrix\n",
    "\n",
    "grid = xr.open_dataset(fh['coral'])\n",
    "grid_data = xr.open_dataset(fh['grid'])\n",
    "\n",
    "template_2d = np.nan*np.ones_like(grid.lsm_w.astype(np.float32))\n",
    "template_3d = np.tile(np.nan*np.ones_like(grid.lsm_w.astype(np.float32))[:, :, np.newaxis], (1, 1, 2))\n",
    "\n",
    "metrics = xr.Dataset(data_vars={# In/out entropy\n",
    "                                'out_ent': (['lat', 'lon', 'mode'], template_3d.copy()),\n",
    "                                'in_ent': (['lat', 'lon', 'mode'], template_3d.copy()),\n",
    "\n",
    "                                # Out/In-strength\n",
    "                                'out_str': (['lat', 'lon', 'mode'], template_3d.copy()),\n",
    "                                'in_str': (['lat', 'lon', 'mode'], template_3d.copy()),\n",
    "\n",
    "                                # Out/In consistency\n",
    "                                'out_con': (['lat', 'lon'], template_2d.copy()),\n",
    "                                'in_con': (['lat', 'lon'], template_2d.copy()),\n",
    "\n",
    "                                # Betweenness centrality\n",
    "                                'btw_cen': (['lat', 'lon', 'mode'], template_3d.copy())},\n",
    "\n",
    "                     coords={'lon': (['lon'], grid.lon_rho_w.values),\n",
    "                             'lon_bnd': (['lon_bnd'], np.concatenate([np.array([2*grid.lon_rho_w.values[0] -\n",
    "                                                                                grid.lon_rho_w.values[1]]),\n",
    "                                                                      grid.lon_rho_w.values,\n",
    "                                                                      np.array([2*grid.lon_rho_w.values[-1] -\n",
    "                                                                                grid.lon_rho_w.values[-2]])])),\n",
    "                             'lat': (['lat'], grid.lat_rho_w.values),\n",
    "                             'lat_bnd': (['lat_bnd'], np.concatenate([np.array([2*grid.lat_rho_w.values[0] -\n",
    "                                                                                grid.lat_rho_w.values[1]]),\n",
    "                                                                      grid.lat_rho_w.values,\n",
    "                                                                      np.array([2*grid.lat_rho_w.values[-1] -\n",
    "                                                                                grid.lat_rho_w.values[-2]])])),\n",
    "                             'mode': (['mode'], ['day', 'full'])}\n",
    "                     )\n",
    "\n",
    "template_2d = np.nan*np.ones((len(cell_list)))\n",
    "template_3d = np.nan*np.ones((len(cell_list), 2))\n",
    "\n",
    "metrics_raw = xr.Dataset(data_vars={# In/out entropy\n",
    "                                    'out_ent': (['cell', 'mode'], template_3d.copy()),\n",
    "                                    'in_ent': (['cell', 'mode'], template_3d.copy()),\n",
    "\n",
    "                                    # Out/In-strength\n",
    "                                    'out_str': (['cell', 'mode'], template_3d.copy()),\n",
    "                                    'in_str': (['cell', 'mode'], template_3d.copy()),\n",
    "\n",
    "                                    # Out/In-consistency\n",
    "                                    'out_con': (['cell'], template_2d.copy()),\n",
    "                                    'in_con': (['cell'], template_2d.copy()),\n",
    "\n",
    "                                    # Betweenness centrality\n",
    "                                    'btw_cen': (['cell', 'mode'], template_3d.copy())},\n",
    "\n",
    "                         coords={'cell': (['cell'], cell_list),\n",
    "                                 'mode': (['mode'], ['day', 'full'])}\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cfc56a-3d1a-413d-bfb7-2de11603bd94",
   "metadata": {},
   "source": [
    "- 111224 Finished here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd0cdd2d-b1f1-42c1-b78b-f13efcca2053",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiaruizhou/.conda/envs/parcels_env/lib/python3.13/site-packages/xarray/backends/api.py:365: UserWarning: The specified chunks separate the stored chunks along dimension \"time\" starting at index 1000. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  var_chunks = _get_chunk(var, chunks, chunkmanager)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......Computing entropy......\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "new dimensions ('cell',) must be a superset of existing dimensions ('source_cell',)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 87\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m......Computing entropy......\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Compute the full entropy\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m \u001b[43mmetrics_raw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_ent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfull\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(src_flux\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog2(_src_flux))\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msink_cell\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     88\u001b[0m metrics_raw\u001b[38;5;241m.\u001b[39min_ent\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(snk_flux\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog2(_snk_flux))\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_cell\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Compute median daily entropy\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/parcels_env/lib/python3.13/site-packages/xarray/core/dataarray.py:269\u001b[0m, in \u001b[0;36m_LocIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    266\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_array\u001b[38;5;241m.\u001b[39mdims, labels, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m    268\u001b[0m dim_indexers \u001b[38;5;241m=\u001b[39m map_index_queries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_array, key)\u001b[38;5;241m.\u001b[39mdim_indexers\n\u001b[0;32m--> 269\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_array\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdim_indexers\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[0;32m~/.conda/envs/parcels_env/lib/python3.13/site-packages/xarray/core/dataarray.py:919\u001b[0m, in \u001b[0;36mDataArray.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;66;03m# DataArray key -> Variable key\u001b[39;00m\n\u001b[1;32m    915\u001b[0m key \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    916\u001b[0m     k: v\u001b[38;5;241m.\u001b[39mvariable \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, DataArray) \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_item_key_to_dict(key)\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    918\u001b[0m }\n\u001b[0;32m--> 919\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[0;32m~/.conda/envs/parcels_env/lib/python3.13/site-packages/xarray/core/variable.py:888\u001b[0m, in \u001b[0;36mVariable.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    886\u001b[0m         value \u001b[38;5;241m=\u001b[39m Variable(dims[\u001b[38;5;241m-\u001b[39mvalue\u001b[38;5;241m.\u001b[39mndim :], value)\n\u001b[1;32m    887\u001b[0m \u001b[38;5;66;03m# broadcast to become assignable\u001b[39;00m\n\u001b[0;32m--> 888\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_order:\n\u001b[1;32m    891\u001b[0m     value \u001b[38;5;241m=\u001b[39m duck_array_ops\u001b[38;5;241m.\u001b[39masarray(value)\n",
      "File \u001b[0;32m~/.conda/envs/parcels_env/lib/python3.13/site-packages/xarray/util/deprecation_helpers.py:143\u001b[0m, in \u001b[0;36mdeprecate_dims.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     emit_user_level_warning(\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` argument has been renamed to `dim`, and will be removed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the future. This renaming is taking place throughout xarray over the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;167;01mPendingDeprecationWarning\u001b[39;00m,\n\u001b[1;32m    141\u001b[0m     )\n\u001b[1;32m    142\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdim\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(old_name)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/parcels_env/lib/python3.13/site-packages/xarray/core/variable.py:1380\u001b[0m, in \u001b[0;36mVariable.set_dims\u001b[0;34m(self, dim, shape)\u001b[0m\n\u001b[1;32m   1378\u001b[0m missing_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(dim)\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_dims:\n\u001b[0;32m-> 1380\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1381\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew dimensions \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m must be a superset of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1382\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexisting dimensions \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m     )\n\u001b[1;32m   1385\u001b[0m self_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims)\n\u001b[1;32m   1386\u001b[0m expanded_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dim \u001b[38;5;28;01mif\u001b[39;00m d \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m self_dims) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims\n",
      "\u001b[0;31mValueError\u001b[0m: new dimensions ('cell',) must be a superset of existing dimensions ('source_cell',)"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# ENTROPY #####################################################################\n",
    "###############################################################################\n",
    "\n",
    "print('......Computing entropy......')\n",
    "\n",
    "# Compute the full entropy\n",
    "metrics_raw.out_ent.loc[:, 'full'] = -(src_flux*np.log2(_src_flux)).sum(dim='sink_cell')\n",
    "metrics_raw.in_ent.loc[:, 'full'] = -(snk_flux*np.log2(_snk_flux)).sum(dim='source_cell')\n",
    "\n",
    "# Compute median daily entropy\n",
    "with xr.open_dataset(fh['entropy_matrix']['out'], chunks={'source_cell': 1000}) as file:\n",
    "    file = reorder(file)\n",
    "    metrics_raw.out_ent.loc[:, 'day'] = file.entropy[:, file.time.dt.month.isin(spawning_months)].quantile(0.5, dim='time').compute()\n",
    "\n",
    "with xr.open_dataset(fh['entropy_matrix']['in'], chunks={'sink_cell': 1000}) as file:\n",
    "    file = reorder(file)\n",
    "    metrics_raw.in_ent.loc[:, 'day'] = file.entropy[:, file.time.dt.month.isin(spawning_months)].quantile(0.5, dim='time').compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb83379b-3859-4a8e-b364-0a2f1e445fa5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Processing Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40a442ec-beff-4338-a94a-a4b9abcd0d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......Computing entropy......\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "new dimensions ('cell',) must be a superset of existing dimensions ('source_cell',)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m......Computing entropy......\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Compute the full entropy\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmetrics_raw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_ent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfull\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(src_flux\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog2(_src_flux))\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msink_cell\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m metrics_raw\u001b[38;5;241m.\u001b[39min_ent\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(snk_flux\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog2(_snk_flux))\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_cell\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Compute median daily entropy\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/parcels_env/lib/python3.13/site-packages/xarray/core/dataarray.py:269\u001b[0m, in \u001b[0;36m_LocIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    266\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_array\u001b[38;5;241m.\u001b[39mdims, labels, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m    268\u001b[0m dim_indexers \u001b[38;5;241m=\u001b[39m map_index_queries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_array, key)\u001b[38;5;241m.\u001b[39mdim_indexers\n\u001b[0;32m--> 269\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_array\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdim_indexers\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[0;32m~/.conda/envs/parcels_env/lib/python3.13/site-packages/xarray/core/dataarray.py:919\u001b[0m, in \u001b[0;36mDataArray.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;66;03m# DataArray key -> Variable key\u001b[39;00m\n\u001b[1;32m    915\u001b[0m key \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    916\u001b[0m     k: v\u001b[38;5;241m.\u001b[39mvariable \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, DataArray) \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_item_key_to_dict(key)\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    918\u001b[0m }\n\u001b[0;32m--> 919\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[0;32m~/.conda/envs/parcels_env/lib/python3.13/site-packages/xarray/core/variable.py:888\u001b[0m, in \u001b[0;36mVariable.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    886\u001b[0m         value \u001b[38;5;241m=\u001b[39m Variable(dims[\u001b[38;5;241m-\u001b[39mvalue\u001b[38;5;241m.\u001b[39mndim :], value)\n\u001b[1;32m    887\u001b[0m \u001b[38;5;66;03m# broadcast to become assignable\u001b[39;00m\n\u001b[0;32m--> 888\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_order:\n\u001b[1;32m    891\u001b[0m     value \u001b[38;5;241m=\u001b[39m duck_array_ops\u001b[38;5;241m.\u001b[39masarray(value)\n",
      "File \u001b[0;32m~/.conda/envs/parcels_env/lib/python3.13/site-packages/xarray/util/deprecation_helpers.py:143\u001b[0m, in \u001b[0;36mdeprecate_dims.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     emit_user_level_warning(\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` argument has been renamed to `dim`, and will be removed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the future. This renaming is taking place throughout xarray over the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;167;01mPendingDeprecationWarning\u001b[39;00m,\n\u001b[1;32m    141\u001b[0m     )\n\u001b[1;32m    142\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdim\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(old_name)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/parcels_env/lib/python3.13/site-packages/xarray/core/variable.py:1380\u001b[0m, in \u001b[0;36mVariable.set_dims\u001b[0;34m(self, dim, shape)\u001b[0m\n\u001b[1;32m   1378\u001b[0m missing_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(dim)\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_dims:\n\u001b[0;32m-> 1380\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1381\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew dimensions \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m must be a superset of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1382\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexisting dimensions \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m     )\n\u001b[1;32m   1385\u001b[0m self_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims)\n\u001b[1;32m   1386\u001b[0m expanded_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dim \u001b[38;5;28;01mif\u001b[39;00m d \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m self_dims) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims\n",
      "\u001b[0;31mValueError\u001b[0m: new dimensions ('cell',) must be a superset of existing dimensions ('source_cell',)"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# ENTROPY #####################################################################\n",
    "###############################################################################\n",
    "\n",
    "print('......Computing entropy......')\n",
    "\n",
    "# Compute the full entropy\n",
    "metrics_raw.out_ent.loc[:, 'full'] = -(src_flux*np.log2(_src_flux)).sum(dim='sink_cell')\n",
    "metrics_raw.in_ent.loc[:, 'full'] = -(snk_flux*np.log2(_snk_flux)).sum(dim='source_cell')\n",
    "\n",
    "# Compute median daily entropy\n",
    "with xr.open_dataset(fh['entropy_matrix']['out'], chunks={'source_cell': 1000}) as file:\n",
    "    file = reorder(file)\n",
    "    metrics_raw.out_ent.loc[:, 'day'] = file.entropy[:, file.time.dt.month.isin(spawning_months)].quantile(0.5, dim='time').compute()\n",
    "\n",
    "with xr.open_dataset(fh['entropy_matrix']['in'], chunks={'sink_cell': 1000}) as file:\n",
    "    file = reorder(file)\n",
    "    metrics_raw.in_ent.loc[:, 'day'] = file.entropy[:, file.time.dt.month.isin(spawning_months)].quantile(0.5, dim='time').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a455b3c-3420-43dd-be4f-3cefa0798238",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# STRENGTH ####################################################################\n",
    "###############################################################################\n",
    "\n",
    "print('.....Computing strength......')\n",
    "\n",
    "with xr.open_dataset(fh['str_matrix']['src'], chunks={'source_cell': 1000}) as file:\n",
    "    file = reorder(file)\n",
    "    metrics_raw.out_str.loc[:, 'full'] = (file.ns/file.rc)[:, file.time.dt.month.isin(spawning_months)].mean(dim='time').compute()\n",
    "    metrics_raw.out_str.loc[:, 'day'] = (file.ns/file.rc)[:, file.time.dt.month.isin(spawning_months)].quantile(0.5, dim='time').compute()\n",
    "\n",
    "with xr.open_dataset(fh['str_matrix']['snk'], chunks={'sink_cell': 1000}) as file:\n",
    "    file = reorder(file)\n",
    "    metrics_raw.in_str.loc[:, 'full'] = (file.ns/file.rc)[:, file.time.dt.month.isin(spawning_months)].mean(dim='time').compute()\n",
    "    metrics_raw.in_str.loc[:, 'day'] = (file.ns/file.rc)[:, file.time.dt.month.isin(spawning_months)].quantile(0.5, dim='time').compute()\n",
    "\n",
    "###############################################################################\n",
    "# consistency ####################################################################\n",
    "###############################################################################\n",
    "\n",
    "print('.....Computing consistency......')\n",
    "with xr.open_dataset(fh['str_matrix']['src'], chunks={'source_cell': 1000}) as file:\n",
    "    file = reorder(file)\n",
    "    n_days = int(file.time.dt.month.isin(spawning_months).sum())\n",
    "    metrics_raw.out_con.data = np.argmax((np.sort(file.ns[:, file.time.dt.month.isin(spawning_months)], axis=-1)[:, ::-1].cumsum(axis=-1)\n",
    "                                          >= 0.5*file.ns[:, file.time.dt.month.isin(spawning_months)].sum(dim='time').values.reshape(-1, 1)), axis=-1)/n_days\n",
    "\n",
    "\n",
    "with xr.open_dataset(fh['str_matrix']['snk'], chunks={'sink_cell': 1000}) as file:\n",
    "    file = reorder(file)\n",
    "    metrics_raw.in_con.data = np.argmax((np.sort(file.ns[:, file.time.dt.month.isin(spawning_months)], axis=-1)[:, ::-1].cumsum(axis=-1)\n",
    "                                          >= 0.5*file.ns[:, file.time.dt.month.isin(spawning_months)].sum(dim='time').values.reshape(-1, 1)), axis=-1)/n_days\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# BETWEENNESS CENTRALITY ######################################################\n",
    "###############################################################################\n",
    "\n",
    "print('')\n",
    "print('...Computing btw centrality..')\n",
    "log_flux = -np.log10(_flux_grp_mean.where(_flux_grp_mean > 0).fillna(1e-20).values)\n",
    "graph = nx.from_numpy_array(log_flux, create_using=nx.DiGraph)\n",
    "graph = nx.relabel_nodes(graph, {i: int(grp_list[i]) for i in range(len(grp_list))})\n",
    "\n",
    "btw_template = np.nan*xr.ones_like(metrics_raw.out_con)\n",
    "btw_template = btw_template.assign_coords({'cell': np.floor(btw_template.cell/2**8).astype(int)})\n",
    "_btw_cen_full = btw_template.copy()\n",
    "\n",
    "# Mean picture\n",
    "_btw_cen_full_ = nx.betweenness_centrality(graph, weight='weight')\n",
    "\n",
    "for group in grp_list:\n",
    "    _btw_cen_full.loc[group] = _btw_cen_full_[group]\n",
    "\n",
    "metrics_raw.btw_cen.loc[:, 'full'] = _btw_cen_full.assign_coords({'cell': cell_list})\n",
    "\n",
    "# Compute betweenness centrality across iterations, and take the median\n",
    "n_its = 100\n",
    "_btw_cen_day = xr.DataArray(data=np.nan*np.ones((len(cell_list), n_its)),\n",
    "                           dims=['cell', 'iteration'],\n",
    "                           coords={'cell': (['cell'], cell_list),\n",
    "                                   'iteration': (['iteration'], np.arange(n_its))})\n",
    "_btw_cen_day = _btw_cen_day.assign_coords({'cell': np.floor(_btw_cen_day.cell/2**8).astype(int)})\n",
    "\n",
    "np.random.seed(1234)\n",
    "random_slices = np.random.choice(np.arange(len(_flux_grp.time)), size=(n_its,))\n",
    "\n",
    "for it in tqdm(range(n_its), total=n_its):\n",
    "    submatrix = _flux_grp[:, :, random_slices[it]].drop('time')\n",
    "    log_flux = -np.log10(submatrix.where(submatrix > 0).fillna(1e-20).values)\n",
    "    graph = nx.from_numpy_array(log_flux, create_using=nx.DiGraph)\n",
    "    graph = nx.relabel_nodes(graph, {i: int(grp_list[i]) for i in range(len(grp_list))})\n",
    "\n",
    "    _btw_cen_day_ = nx.betweenness_centrality(graph, weight='weight')\n",
    "\n",
    "    for group in grp_list:\n",
    "        _btw_cen_day.loc[group, it] = _btw_cen_day_[group]\n",
    "\n",
    "_btw_cen_day = _btw_cen_day.assign_coords({'cell': cell_list})\n",
    "metrics_raw.btw_cen.loc[:, 'day'] = _btw_cen_day.median(dim='iteration')\n",
    "\n",
    "###############################################################################\n",
    "# GRIDDING ####################################################################\n",
    "###############################################################################\n",
    "\n",
    "print('')\n",
    "print('..........Gridding...........')\n",
    "\n",
    "for idx in tqdm(cell_list, total=len(cell_list)):\n",
    "    idx_loc = np.where(grid.reef_idx_w == idx)\n",
    "\n",
    "    for metric in ['out_ent', 'in_ent', 'out_str', 'in_str', 'btw_cen']:\n",
    "        for mode in ['day', 'full']:\n",
    "            metrics[metric].loc[:, :, mode][idx_loc] = metrics_raw[metric].loc[idx, mode]\n",
    "\n",
    "    for metric in ['out_con', 'in_con']:\n",
    "        metrics[metric][idx_loc] = metrics_raw[metric].loc[idx]\n",
    "\n",
    "print('')\n",
    "\n",
    "metrics.to_netcdf(dirs['ref'] + 'Metrics/' + bio_code + '_gridded_metrics.nc', encoding={var: {'zlib': True, 'complevel': 5} for var in metrics.variables})\n",
    "metrics_raw.to_netcdf(dirs['ref'] + 'Metrics/' + bio_code + '_metrics.nc', encoding={var: {'zlib': True, 'complevel': 5} for var in metrics_raw.variables})\n",
    "\n",
    "###############################################################################\n",
    "# PLOTTING ####################################################################\n",
    "###############################################################################\n",
    "\n",
    "print('@>-------------------------<@')\n",
    "print('...........Plotting..........')\n",
    "\n",
    "# Set up grids\n",
    "lon_bnd = grid.lon_psi_w.values\n",
    "dlon = np.ediff1d(lon_bnd[:2])\n",
    "lon_bnd = np.concatenate([lon_bnd[0]-dlon, lon_bnd, lon_bnd[-1]+dlon])\n",
    "\n",
    "lat_bnd = grid.lat_psi_w.values\n",
    "dlat = np.ediff1d(lat_bnd[:2])\n",
    "lat_bnd = np.concatenate([lat_bnd[0]-dlat, lat_bnd, lat_bnd[-1]+dlat])\n",
    "\n",
    "def plot_overview(matrix, vmin, vmax, log, label, fh, cmap):\n",
    "    f = plt.figure(figsize=(8.6, 4.6))\n",
    "    gs = GridSpec(1, 2, figure=f, width_ratios=[1.0, 0.025], wspace=0.05, hspace=0.04)\n",
    "    ax = []\n",
    "    ax.append(f.add_subplot(gs[0, 0], projection = ccrs.PlateCarree()))   # Overview\n",
    "    ax.append(f.add_subplot(gs[0, 1]))   # cbar\n",
    "\n",
    "    gl = []\n",
    "    reef_plots = []\n",
    "\n",
    "    # Create the overview plot first\n",
    "    ax[0].pcolormesh(lon_bnd, lat_bnd, grid.lsm_w.where(grid.lsm_w == 1),\n",
    "                      vmin=0, vmax=1, cmap=cmr.neutral_r, rasterized=True, zorder=5)\n",
    "    if log:\n",
    "        reef_plots.append(ax[0].pcolormesh(lon_bnd, lat_bnd, matrix,\n",
    "                                           norm=colors.LogNorm(vmin=vmin, vmax=vmax),\n",
    "                                           cmap=cmap, zorder=2))\n",
    "    else:\n",
    "        reef_plots.append(ax[0].pcolormesh(lon_bnd, lat_bnd, matrix,\n",
    "                                           vmin=vmin, vmax=vmax,\n",
    "                                           cmap=cmap, zorder=2))\n",
    "\n",
    "    gl.append(ax[0].gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                              linewidth=0.5, color='k', linestyle='-',\n",
    "                              alpha=0.5, zorder=4))\n",
    "    gl[0].xlocator = mticker.FixedLocator(np.arange(-210, 210, 5))\n",
    "    gl[0].ylocator = mticker.FixedLocator(np.arange(-90, 120, 5))\n",
    "    gl[0].top_labels = False\n",
    "    gl[0].right_labels = False\n",
    "    gl[0].ylabel_style = {'size': 8}\n",
    "    gl[0].xlabel_style = {'size': 8}\n",
    "\n",
    "    # Background colour key\n",
    "    cbar = plt.colorbar(reef_plots[0], cax=ax[1], orientation='vertical')\n",
    "    ax[1].tick_params(axis='y', labelsize=8, pad=0.01)\n",
    "    cbar.set_label(label, size=10, labelpad=1)\n",
    "\n",
    "    plt.savefig(dirs['fig'] + 'Metrics/Overview/' + bio_code + '/' + bio_code + '_' + fh + '.png', bbox_inches='tight', dpi=1200)\n",
    "    plt.close()\n",
    "\n",
    "def plot_close(matrix, vmin, vmax, log, label, fh, cmap):\n",
    "    f = plt.figure(figsize=(8.0, 9.2))\n",
    "    gs = GridSpec(9, 3, figure=f, width_ratios=[0.42, 1.0, 0.53],\n",
    "                  height_ratios=[0.41, 0.04, 0.19, 0.04, 0.308, 0.04, 0.308, 0.04, 0.03], wspace=0.22, hspace=0.05)\n",
    "    ax = []\n",
    "    ax.append(f.add_subplot(gs[0:3, 0], projection = ccrs.PlateCarree())) # EACC1\n",
    "    ax.append(f.add_subplot(gs[0, 1], projection = ccrs.PlateCarree()))   # Seychelles (inner)\n",
    "    ax.append(f.add_subplot(gs[2, 1], projection = ccrs.PlateCarree()))   # Seychelles (outer)\n",
    "    ax.append(f.add_subplot(gs[0:3, 2], projection = ccrs.PlateCarree())) # Chagos\n",
    "    ax.append(f.add_subplot(gs[4:7, 0], projection = ccrs.PlateCarree())) # EACC2\n",
    "    ax.append(f.add_subplot(gs[4, 1], projection = ccrs.PlateCarree()))   # Comoros\n",
    "    ax.append(f.add_subplot(gs[4, 2], projection = ccrs.PlateCarree()))   # N Madagascar\n",
    "    ax.append(f.add_subplot(gs[6, 1], projection = ccrs.PlateCarree()))   # Reunion/Mauritius\n",
    "    ax.append(f.add_subplot(gs[6, 2], projection = ccrs.PlateCarree()))   # S Madagascar\n",
    "    ax.append(f.add_subplot(gs[8, :]))                                    # CBAR\n",
    "\n",
    "    # Plot data\n",
    "    gl = []\n",
    "    reef_plots = []\n",
    "\n",
    "    # Add elements to each panel\n",
    "    for i in range(9):\n",
    "        ax[i].contourf(grid_data.lon_rho, grid_data.lat_rho, grid_data.h, levels=np.arange(0, 6000, step=250),\n",
    "                       cmap=cmr.get_sub_cmap(cmr.ocean_r, 0, 0.6), zorder=0)\n",
    "        ax[i].pcolormesh(lon_bnd, lat_bnd, 1 - grid.lsm_w.where(grid.lsm_w == 1),\n",
    "                         vmin=0, vmax=1, cmap=cmr.neutral, rasterized=True, zorder=5)\n",
    "        if log:\n",
    "            reef_plots.append(ax[i].pcolormesh(lon_bnd, lat_bnd, matrix,\n",
    "                                               norm=colors.LogNorm(vmin=vmin, vmax=vmax),\n",
    "                                               cmap=cmap, zorder=5))\n",
    "        else:\n",
    "            reef_plots.append(ax[i].pcolormesh(lon_bnd, lat_bnd, matrix,\n",
    "                                               vmin=vmin, vmax=vmax,\n",
    "                                               cmap=cmap, zorder=5))\n",
    "        gl.append(ax[i].gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                                  linewidth=0.5, color='k', linestyle='--', zorder=4,\n",
    "                                  ypadding=2, xpadding=2))\n",
    "        gl[i].xlocator = mticker.FixedLocator(np.arange(-210, 210, 1))\n",
    "        gl[i].ylocator = mticker.FixedLocator(np.arange(-90, 120, 1))\n",
    "\n",
    "        if i < 4:\n",
    "            gl[i].bottom_labels = False\n",
    "        else:\n",
    "            gl[i].top_labels = False\n",
    "\n",
    "        gl[i].right_labels = False\n",
    "        gl[i].ylabel_style = {'size': 8}\n",
    "        gl[i].xlabel_style = {'size': 8}\n",
    "\n",
    "    # Panel extents\n",
    "    ax[0].set_extent([38.7, 40.2, -8.8, -4.5])     # EACC1\n",
    "    ax[1].set_extent([52.6, 56.4, -6.67, -4.0])    # Seychelles (inner)\n",
    "    ax[2].set_extent([45.1, 48.9, -10.3, -9.065])  # Aldabra Grp\n",
    "    ax[3].set_extent([70.9, 72.9, -8.3, -4.0])     # Chagos\n",
    "    ax[4].set_extent([39.7, 41.2, -14.5, -10.2])   # EACC2\n",
    "    ax[5].set_extent([43.1, 46.9, -13.2, -11.19])  # Comoros\n",
    "    ax[6].set_extent([47.9, 49.9, -13.8, -11.8])   # N Madagascar\n",
    "    ax[7].set_extent([54.6, 58.4, -21.5, -19.5])   # Mauritius/Reunion\n",
    "    ax[8].set_extent([48.9, 50.9, -17.2, -15.2])   # E Madagascar\n",
    "\n",
    "    # Background colour key\n",
    "    cbar = plt.colorbar(reef_plots[0], cax=ax[9], orientation='horizontal')\n",
    "    ax[9].tick_params(axis='x', labelsize=8, pad=0.01)\n",
    "    cbar.set_label(label, size=10, labelpad=1)\n",
    "\n",
    "    plt.savefig(dirs['fig'] + 'Metrics/Close/'  + bio_code + '/' + bio_code + '_' + fh + '.png', bbox_inches='tight', dpi=600)\n",
    "    plt.close()\n",
    "\n",
    "if plot_full:\n",
    "    # Plot overviews\n",
    "    plot_overview(metrics.out_str.loc[:, :, 'full'], 5e-3, 1e-1, True, 'Out-strength', 'out_str_full', cmr.guppy)\n",
    "    plot_overview(metrics.out_str.loc[:, :, 'day'], 1e-4, 1e-1, True, 'Out-strength', 'out_str_day', cmr.guppy)\n",
    "    plot_overview(metrics.in_str.loc[:, :, 'full'], 5e-3, 1e-1, True, 'In-strength', 'in_str_full', cmr.guppy)\n",
    "    plot_overview(metrics.in_str.loc[:, :, 'day'], 1e-4, 1e-1, True, 'In-strength', 'in_str_day', cmr.guppy)\n",
    "\n",
    "    plot_overview(metrics.out_ent.loc[:, :, 'full'], 4, 10, False, 'Out-entropy (b)', 'out_ent_full', cmr.guppy)\n",
    "    plot_overview(metrics.out_ent.loc[:, :, 'day'], 2, 6, False, 'Out-entropy (b)', 'out_ent_day', cmr.guppy)\n",
    "    plot_overview(metrics.in_ent.loc[:, :, 'full'], 4, 10, False, 'In-entropy (b)', 'in_ent_full', cmr.guppy)\n",
    "    plot_overview(metrics.in_ent.loc[:, :, 'day'], 2, 6, False, 'In-entropy (b)', 'in_ent_day', cmr.guppy)\n",
    "\n",
    "    plot_overview(metrics.out_con*100, 0, 30, False, 'Out-consistency (% spawning events)', 'out_con', cmr.guppy)\n",
    "    plot_overview(metrics.in_con*100, 0, 15, False, 'In-consistency (% spawning events)', 'in_con', cmr.guppy)\n",
    "\n",
    "    plot_overview(metrics.btw_cen.loc[:, :, 'full']*100, 0, 1, False, 'Betweenness centrality (%)', 'btw_cen_full', cmr.guppy)\n",
    "    plot_overview(metrics.btw_cen.loc[:, :, 'day']*100, 0, 1, False, 'Betweenness centrality (%)', 'btw_cen_day', cmr.guppy)\n",
    "\n",
    "    # Plot close-ups\n",
    "    plot_close(metrics.out_str.loc[:, :, 'full'], 5e-3, 1e-1, True, 'Out-strength', 'out_str_full', cmr.guppy)\n",
    "    plot_close(metrics.out_str.loc[:, :, 'day'], 1e-4, 1e-1, True, 'Out-strength', 'out_str_day', cmr.guppy)\n",
    "    plot_close(metrics.in_str.loc[:, :, 'full'], 5e-3, 1e-1, True, 'In-strength', 'in_str_full', cmr.guppy)\n",
    "    plot_close(metrics.in_str.loc[:, :, 'day'], 1e-4, 1e-1, True, 'In-strength', 'in_str_day', cmr.guppy)\n",
    "\n",
    "    plot_close(metrics.out_ent.loc[:, :, 'full'], 4, 10, False, 'Out-entropy (b)', 'out_ent_full', cmr.guppy)\n",
    "    plot_close(metrics.out_ent.loc[:, :, 'day'], 2, 6, False, 'Out-entropy (b)', 'out_ent_day', cmr.guppy)\n",
    "    plot_close(metrics.in_ent.loc[:, :, 'full'], 4, 10, False, 'In-entropy (b)', 'in_ent_full', cmr.guppy)\n",
    "    plot_close(metrics.in_ent.loc[:, :, 'day'], 2, 6, False, 'In-entropy (b)', 'in_ent_day', cmr.guppy)\n",
    "\n",
    "    plot_close(metrics.out_con*100, 0, 30, False, 'Out-consistency (% spawning events)', 'out_con', cmr.guppy)\n",
    "    plot_close(metrics.in_con*100, 0, 15, False, 'In-consistency (% spawning events)', 'in_con', cmr.guppy)\n",
    "\n",
    "    plot_close(metrics.btw_cen.loc[:, :, 'full']*100, 0, 1, False, 'Betweenness centrality (%)', 'btw_cen_full', cmr.guppy)\n",
    "    plot_close(metrics.btw_cen.loc[:, :, 'day']*100, 0, 1, False, 'Betweenness centrality (%)', 'btw_cen_day', cmr.guppy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (parcels_3.1.0)",
   "language": "python",
   "name": "parcels_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
